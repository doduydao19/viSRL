import torch
from transformers import AutoModel, AutoTokenizer

phobert = AutoModel.from_pretrained("vinai/phobert-base-v2")
tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base-v2")

print(len(tokenizer.get_vocab()))

#
# # INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!
# sentence = 'Chúng_tôi là những nghiên_cứu_viên .'
#
# input_ids = torch.tensor([tokenizer.encode(sentence)])
#
# with torch.no_grad():
#     features = phobert(input_ids)  # Models outputs are now tuples
#
